# Learning to Pick by Digging: Data-Driven Dig-Grasping

**Paper** can be seen from this [link](https://drive.google.com/file/d/1Gt1lGLKViwA0VUo-j-2dNF4c3S8ATnv_/view?usp=sharing).

If you use PyBullet in your research, please cite it like this:

```
@inproceedings{learntodig2022,
  title={Learning to Pick by Digging: Data-Driven Dig-Grasping for BinPicking from Clutter},
  author={Zhao, Chao  and Tong, Zhekai and Rojas, Juan and  Seo, Jungwon},
  booktitle={2022 IEEE International Conference on Robotics and Automation (ICRA)},
  year={2022},
  organization={IEEE}
}
```

## 1. Overview
In this work, we propsoe a learning framework for a manipulation technique to bin picking, named **Dig-Grasping**, which aims at singulating and simultaneously picking the objects one by one from a random clutter. Dig-grasping illustrates a way of grasping through a physical interaction between the robot's gripper and object clutter, realized as a digging operation along a straight line. A gripper designed for this technique is capable of changing relative digit lengths such that the object being digged will not collide with the other finger. This repository provides the PyTorch implementation for 

### Code and Extras

You can find additional resources on [Github]. (Coming Soon) Includes:  
  

-   The  Benchmark
-   Paper code (architectures, losses, dataloaders, etc.)
-   Model weights
